pipeline {
  agent any

  parameters {
    string(
      name: 'DAG_ID',
      defaultValue: 'team_a_dev_iris_pipeline',
      description: 'Airflow DAG ID to trigger'
    )
    choice(
      name: 'ENV',
      choices: ['dev', 'stage', 'prod'],
      description: 'Logical environment label (for conf tagging)'
    )
    string(
      name: 'RUN_ID_PREFIX',
      defaultValue: 'jenkins_manual',
      description: 'Prefix for dag_run_id (timestamp is appended)'
    )
    text(
      name: 'DAG_CONF_JSON',
      defaultValue: '',
      description: 'Optional JSON for dag_run.conf (leave empty to use default)'
    )
  }

  environment {
    AIRFLOW_BASE_URL = "http://airflow-webserver:8080"
  }

  stages {
    stage('Checkout Platform Repo') {
      steps {
        checkout scm
      }
    }

    stage('Trigger Airflow DAG via Python') {
      steps {
        withCredentials([
          usernamePassword(
            credentialsId: 'airflow-basic-auth',
            usernameVariable: 'AIRFLOW_USERNAME',
            passwordVariable: 'AIRFLOW_PASSWORD'
          )
        ]) {
          sh '''#!/usr/bin/env bash
            set -euo pipefail

            cd "${WORKSPACE}"

            echo "==> Running Python DAG trigger"
            python3 scripts/trigger_airflow_dag.py \
              --airflow-base-url "${AIRFLOW_BASE_URL}" \
              --dag-id "${DAG_ID}" \
              --env "${ENV}" \
              --run-id-prefix "${RUN_ID_PREFIX}" \
              ${DAG_CONF_JSON:+"--conf-json ${DAG_CONF_JSON}"}
          '''
        }
      }
    }
  }

  post {
    success {
      echo "SUCCESS: Triggered DAG ${params.DAG_ID} in env=${params.ENV}"
    }
    failure {
      echo "FAILURE: Could not trigger DAG ${params.DAG_ID}"
    }
  }
}
